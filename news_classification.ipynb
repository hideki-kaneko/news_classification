{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニュース記事分類\n",
    "\n",
    "ライブドアニュースコーパス（ https://www.rondhuit.com/download.html )を分類します。同コーパスをダウンロードして解凍すると出てくるtextフォルダがこのノートと同じディレクトリにあると仮定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import MeCab\n",
    "\n",
    "mecab = MeCab.Tagger(\"-Ochasen -d /usr/lib/mecab/dic/mecab-ipadic-neologd/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込みと形態素解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# コーパスのパス\n",
    "path = \"text/\"\n",
    "\n",
    "dirs = [i for i in os.listdir(path) if os.path.isdir(os.path.join(path, i))]\n",
    "original = []\n",
    "corpus = []\n",
    "labels = []\n",
    "label_to_class = {i:j for i,j in enumerate(dirs)}\n",
    "for i, d in enumerate(tqdm(dirs)):\n",
    "    p = os.path.join(path, d)\n",
    "    files = [i for i in os.listdir(p) if i[-4:]==\".txt\" and i!=\"LICENSE.txt\"]\n",
    "    for f in files:\n",
    "        with open(os.path.join(p, f), encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()[2:]\n",
    "            lines = \"\".join(lines).replace(\"\\n\",\"\")\n",
    "            original.append(lines)\n",
    "            node = mecab.parseToNode(lines)\n",
    "            wakati = []\n",
    "            while node:\n",
    "                f = node.feature.split(\",\")[0]\n",
    "                if f in [\"名詞\"]: # 今回は名詞のみ抽出した\n",
    "                    wakati.append(node.surface)\n",
    "                node = node.next\n",
    "            wakati = \" \".join(wakati)\n",
    "            wakati\n",
    "            corpus.append(wakati)\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDFの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=1, max_features=3000) # とりあえず3000次元とした\n",
    "vector = vectorizer.fit_transform(corpus)\n",
    "vector = vector.toarray()\n",
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次元削減"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 100)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=100) # とりあえず100次元とした\n",
    "red_vector = pca.fit_transform(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 500}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9421745622370028"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'C':[100, 200, 300, 400, 500, 600] #80\n",
    "}\n",
    "clf = GridSearchCV(svm.SVC(), parameters, n_jobs=-1)\n",
    "clf.fit(red_vector, labels)\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.predict(red_vector)\n",
    "accuracy_score(labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クロスバリデーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精度: 0.8809429403686003 (+- 0.038053964794232266 )\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, red_vector, labels, cv=5)\n",
    "print(\"精度:\", scores.mean(), \"(+-\", scores.std(), \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各カテゴリの代表文章抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カテゴリ:  dokujo-tsushin\n",
      "典型的な文章（特徴: ガール,ネット,全員,友達,チェック )\n",
      "森ガールよりもリア充？ 「雲ガール」の実態に迫る秋深き　隣は何を　する人ぞ　——。これまで「森ガール」にはじまり「山ガール」、「釣りガール」とさまざまな流行を生みだしてきた“○○ガールズ”ブーム。20 …\n",
      "---------------\n",
      "カテゴリ:  it-life-hack\n",
      "典型的な文章（特徴: 機能,レビュー,リモコン,ホーム,設定 )\n",
      "ようこそ、ケーブルのない世界へ！クリアな音質のBluetooth対応ヘッドセット【新スタイル活用術】「Bluetooth（ブルートゥース）」は、デジタル機器同士を接続するための無線規格だ。Blueto …\n",
      "---------------\n",
      "カテゴリ:  kaden-channel\n",
      "典型的な文章（特徴: hd,制作,映像,レンジ,所有 )\n",
      "【Special Report】ミドルレンジのビデオ制作者の有志が 集まって結成したHD Usersが選んだATEM 1M/E Switcher【ビデオSALON】“ミドルレンジ”といわれるビデオ制作 …\n",
      "---------------\n",
      "カテゴリ:  livedoor-homme\n",
      "典型的な文章（特徴: スマホ,ストア,1月,mbps,for )\n",
      "快適なスマホライフのための必須アプリ　昨年12月に発表されたユーキャン新語・流行語大賞でトップテンに選ばれ、日本人の5人に1人が持っているといわれる「スマホ」。MM総研の調査によると、2011年に国内 …\n",
      "---------------\n",
      "カテゴリ:  movie-enter\n",
      "典型的な文章（特徴: 映画,公開,決定,貞子,アベンジャーズ )\n",
      "【週末映画まとめ読み】注目するのは「貞子の野球カード」か「ボーイッシュ美少女の恋愛トーク」か　今週1週間に起こった出来事を振り返る「週末映画まとめ読み」。先週末の動員ランキングは『メン・イン・ブラック …\n",
      "---------------\n",
      "カテゴリ:  peachy\n",
      "典型的な文章（特徴: 旅行,アート,アイテム,バッグ,便利 )\n",
      "旅のおともはかわいくなくちゃ！(c) didi/amanaimages楽しい旅行に行くのに、“イマイチなモノ”と一緒じゃ気分が盛り上がらない！今回は、一緒に旅行に行きたい、かわいいトラベルグッズを集め …\n",
      "---------------\n",
      "カテゴリ:  smax\n",
      "典型的な文章（特徴: optimus,搭載,05,端子,it )\n",
      "コンパクトなのにほぼ全部入り！Xi対応Android 4.0 ICS搭載ドコモスマートフォン「Optimus it L-05D」を写真と動画でチェック【レポート】Optimus it L-05Dを写真 …\n",
      "---------------\n",
      "カテゴリ:  sports-watch\n",
      "典型的な文章（特徴: さん,自分,写真ギャラリー,スタジオ,トーク )\n",
      "「自分から好きとは言う子じゃなかった」 浅田真央の幼少時代を知る番組ADとは？日本テレビ「おしゃれイズム」（27日放送分）では、フィギュアスケートの浅田真央がゲストで出演した様子が放送された。競技中の …\n",
      "---------------\n",
      "カテゴリ:  topic-news\n",
      "典型的な文章（特徴: akb,応援,本当,事実,さん )\n",
      "元AKB指原莉乃、生放送で胸中告白。交際相手のことやネットの書き込みにも言及今月14日に発売された「週刊文春」（6月21日号）では、AKB48・指原莉乃の元カレを名乗る男性が、交際内容を暴露。指原は翌 …\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "labels_array = np.asarray(labels)\n",
    "original = np.asarray(original)\n",
    "\n",
    "for i, j in label_to_class.items():\n",
    "    print(\"カテゴリ: \", j)\n",
    "    idx = np.argmax(vector[labels_array==i].sum(axis=1))\n",
    "    feature_idx = np.argsort(-vector[labels_array==i][idx])[:5]\n",
    "    print(\"典型的な文章（特徴:\", \",\".join([features[i] for i in feature_idx]), \")\")\n",
    "    print(original[labels_array==i][idx][:100], \"…\")\n",
    "    print(\"---------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
